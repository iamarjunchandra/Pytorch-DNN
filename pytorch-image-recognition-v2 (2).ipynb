{"cells":[{"metadata":{},"cell_type":"markdown","source":"Jane, our friend at the bird-watching club, has set up a fleet of cameras in the woods\nsouth of the airport. The cameras are supposed to save a shot when something enters\nthe frame and upload it to the clubâ€™s real-time bird-watching blog. The problem is\nthat a lot of planes coming and going from the airport end up triggering the camera. so Jane spends a lot of time deleting pictures of airplanes from the blog. What she\nneeds is an automated system that throws away the airplane."},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nfrom torch import optim\nfrom torchvision import datasets\nimport torch.nn as nn\nfrom torchvision import transforms\nimport torch.nn.functional as F\nimport matplotlib.pyplot as plt\nimport datetime","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=datasets.CIFAR10(root='data',\n                      train=True,\n                      download=True,\n                      transform=transforms.ToTensor())","execution_count":2,"outputs":[{"output_type":"stream","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88ebf631a8c1447dbd20873e1bbdb7b4"}},"metadata":{}},{"output_type":"stream","text":"Extracting data/cifar-10-python.tar.gz to data\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=datasets.CIFAR10(root='data',\n                      train=False,\n                      download=True,\n                      transform=transforms.ToTensor())","execution_count":3,"outputs":[{"output_type":"stream","text":"Files already downloaded and verified\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_class={\n0:'airplane',\n1:'automobile',\n2:'bird',\n3:'cat',\n4:'deer',\n5:'dog',\n6:'frog',\n7:'horse',\n8:'ship',\n9:'truck'\n}","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img,label=train[99]\nplt.title(label_class[label])\nplt.axis('off')\nplt.imshow(img.permute(1,2,0))","execution_count":5,"outputs":[{"output_type":"stream","text":"\n","name":"stdout"},{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"<matplotlib.image.AxesImage at 0x7fa14007bad0>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"img.shape","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"torch.Size([3, 32, 32])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Since we only need airplane and birds from the Cifar10 dataset which contains 10 different item images, we are going to select only the birds and airplane data from the dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"label_map = {0: 0, 2: 1}\ncifar_2_train=[(img,label_map[label]) for img,label in train if label in [0,2]]\ncifar_2_test=[(img,label_map[label]) for img,label in test if label in [0,2]]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader=DataLoader(cifar_2_train, batch_size=64,shuffle=True)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's try to build a more better convolutional neural network with more channels and add the regularization methods L2 and Dropout to know if they can improve our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 128, kernel_size=3, padding=1)\n        self.drop_out_1=nn.Dropout2d(p=.4)\n        self.conv2 = nn.Conv2d(128, 32, kernel_size=3, padding=1)\n        self.drop_out_2=nn.Dropout2d(p=.4)\n        self.fc1 = nn.Linear(32 * 8 * 8, 64)\n        self.fc2 = nn.Linear(64, 32)\n        self.fc3 = nn.Linear(32, 2)\n    def forward(self, x):\n        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n        out = self.drop_out_1(out)\n        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n        out = self.drop_out_2(out)\n        out = out.view(-1, 32 * 8 * 8)\n        out = torch.tanh(self.fc1(out))\n        out = self.fc2(out)\n        out = self.fc3(out)\n        return out","execution_count":9,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's train the model in GPU"},{"metadata":{"trusted":true},"cell_type":"code","source":"if torch.cuda.is_available():\n    device=torch.device('cuda')\nelse:\n    device=torch.device('cpu')\n    \nmodel = Net().to(device)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer=optim.Adam(model.parameters(),1e-4)\nloss_fn=nn.CrossEntropyLoss()","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n    for epoch in range(1,n_epochs+1):\n        loss_train = 0.0\n        for imgs,labels in train_loader:\n            imgs=imgs.to(device)\n            labels = labels.to(device)\n            output=model(imgs)\n            \n            loss=loss_fn(output, torch.tensor(labels))\n            \n            #L2 Regularization\n            l2_lambda=0.001\n            l2_norm=sum(p.pow(2).sum() for p in model.parameters())\n            loss=loss+l2_lambda*l2_norm\n\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n\n            loss_train += loss.item()\n\n        if epoch == 1 or epoch % 10 == 0:\n            print('{} Epoch {}, Training loss {}'.format(datetime.datetime.now(), epoch,\n                                                         loss_train / len(train_loader)))","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_loop(\nn_epochs = 100,\noptimizer = optimizer,\nmodel = model,\nloss_fn = loss_fn,\ntrain_loader = train_loader)","execution_count":16,"outputs":[{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  if __name__ == '__main__':\n","name":"stderr"},{"output_type":"stream","text":"2021-03-16 17:20:37.822548 Epoch 1, Training loss 0.6667623489525667\n2021-03-16 17:20:46.329826 Epoch 10, Training loss 0.42444847780428113\n2021-03-16 17:20:55.539584 Epoch 20, Training loss 0.37300287965376666\n2021-03-16 17:21:04.643809 Epoch 30, Training loss 0.3406416923756812\n2021-03-16 17:21:14.054858 Epoch 40, Training loss 0.3199609541779111\n2021-03-16 17:21:23.212286 Epoch 50, Training loss 0.2937381872136122\n2021-03-16 17:21:32.378455 Epoch 60, Training loss 0.27243879570323193\n2021-03-16 17:21:41.591833 Epoch 70, Training loss 0.2579378379378349\n2021-03-16 17:21:50.751510 Epoch 80, Training loss 0.24075474319564308\n2021-03-16 17:21:59.933473 Epoch 90, Training loss 0.23007766114678352\n2021-03-16 17:22:09.137707 Epoch 100, Training loss 0.21407077675032768\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loader=DataLoader(cifar_2_test,batch_size=64,shuffle=False)\ntrain_loader=DataLoader(cifar_2_train,batch_size=64,shuffle=False)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validate(model, train_loader, val_loader):\n    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n        correct = 0\n        total = 0\n        with torch.no_grad():\n            for imgs, labels in loader:\n                imgs=imgs.to(device)\n                labels=labels.to(device)\n                outputs = model(imgs)\n                _, predicted = torch.max(outputs, dim=1)\n                total += labels.shape[0]\n                correct += int((predicted == labels).sum())\n        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validate(model, train_loader, test_loader)","execution_count":23,"outputs":[{"output_type":"stream","text":"Accuracy train: 0.95\nAccuracy val: 0.89\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"So my new version has a training set accuracy of 95% and a validation set accuracy of 89%  in detecting birds and airplane accurately. Woohoo! That's cool. I have sucessfully built a highly accurate model that can distinguish airplane and birds in the sky. So, what am I waiting for? Let's save the model. "},{"metadata":{},"cell_type":"markdown","source":"Lets save the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(model.state_dict(), './' + 'birds_vs_airplanes.pt')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To load the model,"},{"metadata":{"trusted":true},"cell_type":"code","source":"loaded_model=Net()\nloaded_model.load_state_dict(torch.load('./'+ 'birds_vs_airplanes.pt',map_location=device))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}